<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>测试论文展示</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #282c34;
            color: white;
            text-align: center;
            padding: 20px;
        }
        section {
            margin: 20px;
        }
        h2 {
            color: #5b5b5b;
        }
        p {
            line-height: 1.6;
            color: #333;
        }
        img {
            max-width: 100%;
            height: auto;
        }
        footer {
            background-color: #282c34;
            color: white;
            text-align: center;
            padding: 10px;
            position: fixed;
            width: 100%;
            bottom: 0;
        }
    </style>
</head>
<body>
    <header>
		<h1>AMKG:Adaptive Multimodal Knowledge Graph Integration for Object-Goal Navigation in Open-World Embodied Systems</h1>
        <!-- 使用你的图片作为标题 -->
        <img src="img/001.png" alt="AMKG:Adaptive Multimodal Knowledge Graph Integration for Object-Goal Navigation in Open-World Embodied Systems">
    </header>

    <section>
        <h2>abstract</h2>
        <p>The \textbf{Embodied Multi-modal Retrieval-Augmented Generation (EMG)} framework addresses the challenges of multi-modal information indexing within adaptive knowledge graphs. EMG improves navigation, retrieval, and decision-making in embodied intelligent robots operating in dynamic environments by continuously updating a multi-modal knowledge graph through feedback from a Vision-Language Model (VLM). EMG creates unified feature representations that enable real-time adaptive responses and support multi-modal reasoning by integrating visual encoders, language models, and graph networks. Experimental results show that EMG significantly outperforms current state-of-the-art models in embodied tasks, demonstrating strong performance in real-world and simulated environments. EMG achieves over 93\% Rank 1 accuracy in cross-modal retrieval tasks on the ARKitScenes and MultiScan datasets. EMG exhibits robust performance in WiFi-based indoor positioning, achieving high precision in multi-floor localization tasks, highlighting its effectiveness in complex spatial contexts. Furthermore, deploying EMG on embedded platforms like the Jetson AGX Orin showcases its efficiency and suitability for real-time reasoning, emphasizing its potential for practical applications in embodied intelligent systems.</p>
    </section>

    <section>
        <h2>论文内容</h2>
        <p>本论文展示了如何通过网页来表达和展示研究成果，强调了网页技术（如 HTML、CSS）的使用，以及如何将相关素材（如图片、视频、PDF）嵌入到页面中。</p>
        
        <!-- 插入图片 -->
        <h3>论文相关图像</h3>
        <img src="your-image.jpg" alt="论文相关图像">

        <!-- 插入视频 -->
        <h3>论文相关视频</h3>
        <video width="640" height="360" controls>
            <source src="mp4/01.mp4" type="video/mp4">
            你的浏览器不支持视频播放。
        </video>

        <!-- 插入PDF文件 -->
        <h3>论文PDF</h3>
        <iframe src="your-paper.pdf" width="100%" height="600px"></iframe>
    </section>

    <footer>
        <p>测试论文展示页面 | <a href="https://github.com/yourusername/your-repository" target="_blank" style="color:white;">GitHub 仓库</a></p>
    </footer>
</body>
</html>
